# @defgroup Hairoad
#
# copyright Seppe Sels 2024
#
# This code is for internal use only (Uantwerpen, project members)
# Bugs, bugfixes and additions to the code need to be reported to Invilab (contact: Seppe Sels)
# @ingroup Hairoad
## This script reads the binary files and text files that are generated by the lidar and camera and converts them to a ply file.


import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import matplotlib
matplotlib.use('Agg')  # <-- SET THE BACKEND HERE
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from plyfile import PlyData, PlyElement
from scipy.ndimage import distance_transform_edt
import open3d as o3d
import cv2

import numpy as np
import open3d as o3d
import os
from plyfile import PlyData, PlyElement

def reshape_points(points, width,height):


    # Calculate the number of points based on the width and height
    number_of_points = height  # Adjust if your definition of the frame changes


    # Read only the first frame data
    # filter out the first frame. select the first number_of_points from points_np
    points_np = points[0:number_of_points * 3]
    #remove the first numberofpoints from points_np
    points_new = points[number_of_points * 3:]
    points_frame = points_np[:number_of_points * 3].reshape(-1, 3)  # Reshape into Nx3

    # Assign the points and colors to the point cloud
    return points_new, points_frame


def read_point_cloud_from_files(file):
    # Construct filenames based on the timestamp
    points_filename = file+".bin"
    colors_filename = file+"_colors.bin"
    textfile_name = file+ ".bin.txt"
    # Read the binary files
    points_np = np.fromfile(points_filename, dtype=np.float64)  # Read all points
    colors_np = np.fromfile(colors_filename, dtype=np.float64)  # Read all colors
    #plot colors_np:
    # plot colors_np:
    plt.plot(colors_np)
    plt.show()


    ## get the 2nd dimension of colors_np and copy it to to the first and third of coloers_np

    points_rgb_list = []
    points_xyz_list = []
    # Read metadata from the text file
    width = height = frame_count = None  # Initialize variables
    with open(textfile_name, "r") as textfile:
        for line in textfile:
            stripped_line = line.strip()
            # Read width and height
            if stripped_line.startswith("width"):
                width = int(stripped_line.split()[1])
                height = int(stripped_line.split()[3])
                points_np, points_xyz = reshape_points(points_np, width, height)
                colors_np, points_rgb = reshape_points(colors_np, width, height)
                #append points_xyz to points_xyz_list
                #append points_rgb to points_rgb_list
                points_xyz_list.append(points_xyz)
                points_rgb_list.append(points_rgb)
            # Read the number of frames
            elif stripped_line.startswith("numberOfFrames"):
                frame_count = int(stripped_line.split()[1])

    for i in range(len(points_rgb_list)):
        # Extract the second dimension (Green channel)
        try:
            green_channel = points_rgb_list[i][:, 1]*255

            # Copy the Green channel to the Red and Blue channels
            min_val = green_channel.min()
            max_val = green_channel.max()
            value_range = max_val - min_val

            if value_range == 0:
                # If all values are the same, you might want to set the channel to all zeros,
                # or all 128, or min_val if it's already within 0-255.
                # Setting to 0 is consistent with the (X-X) numerator.
                green_channel_normalized = np.zeros_like(green_channel, dtype=float)
            else:
                green_channel_normalized = 255 * (green_channel - min_val) / value_range


            points_rgb_list[i][:, 0] = green_channel.astype(np.uint8)
            points_rgb_list[i][:, 1] = green_channel.astype(np.uint8)
            points_rgb_list[i][:, 2] = green_channel.astype(np.uint8)
        except:
            print(f"Error processing colors for frame {i}. Skipping color for this frame.")
            continue

    # Reshape the points and colors
    return points_xyz_list, points_rgb_list
def save_as_ply(image, colors, output_file):
    # Extract X, Y, Z coordinates and colors
    vertices = np.array([tuple(row) for row in image], dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4')])
    colors = np.array([tuple(row) for row in colors], dtype=[('red', 'uint8'), ('green', 'uint8'), ('blue', 'uint8')])

    # Combine vertices and colors
    vertices_with_colors = np.empty(len(vertices), vertices.dtype.descr + colors.dtype.descr)
    for name in vertices.dtype.names:
        vertices_with_colors[name] = vertices[name]
    for name in colors.dtype.names:
        vertices_with_colors[name] = colors[name]

    # Create a PlyElement
    ply_element = PlyElement.describe(vertices_with_colors, 'vertex')

    # Write the PLY file
    PlyData([ply_element]).write(output_file)
def plot_xyz_with_vtk(XYZ, colors):
    # Create a vtkPoints object and insert the points into it
    points = vtk.vtkPoints()
    for i in range(XYZ.shape[0]):
        points.InsertNextPoint(XYZ[i, :])

    # Create a vtkPolyData object and set the points
    polydata = vtk.vtkPolyData()
    polydata.SetPoints(points)

    # Create a vtkUnsignedCharArray object and set the colors
    vtk_colors = vtk.vtkUnsignedCharArray()
    vtk_colors.SetNumberOfComponents(3)
    vtk_colors.SetName("Colors")
    for i in range(colors.shape[0]):
        vtk_colors.InsertNextTuple3(colors[i, 0], colors[i, 1], colors[i, 2])

    # Set the colors to the polydata
    polydata.GetPointData().SetScalars(vtk_colors)

    # Create a vtkVertexGlyphFilter object and set the input data
    vertex_filter = vtk.vtkVertexGlyphFilter()
    vertex_filter.SetInputData(polydata)
    vertex_filter.Update()

    # Create a vtkPolyDataMapper object and set the input connection
    mapper = vtk.vtkPolyDataMapper()
    mapper.SetInputConnection(vertex_filter.GetOutputPort())

    # Create a vtkActor object and set the mapper
    actor = vtk.vtkActor()
    actor.SetMapper(mapper)

    # Create a vtkRenderer object and add the actor
    renderer = vtk.vtkRenderer()
    renderer.AddActor(actor)
    renderer.SetBackground(0.1, 0.2, 0.4)

    # Create a vtkRenderWindow object and add the renderer
    render_window = vtk.vtkRenderWindow()
    render_window.AddRenderer(renderer)

    # Create a vtkRenderWindowInteractor object and set the render window
    render_window_interactor = vtk.vtkRenderWindowInteractor()
    render_window_interactor.SetRenderWindow(render_window)

    # Start the interaction
    render_window.Render()
    render_window_interactor.Start()



def plot_xyz_with_vtk_and_get_depth(XYZ, colors, width=1000, height=1000, point_size=3):
    # Create a vtkPoints object and insert the points into it
    points = vtk.vtkPoints()
    for i in range(XYZ.shape[0]):
        points.InsertNextPoint(XYZ[i, :])

    # Create a vtkPolyData object and set the points
    polydata = vtk.vtkPolyData()
    polydata.SetPoints(points)

    # Create a vtkUnsignedCharArray object and set the colors
    vtk_colors = vtk.vtkUnsignedCharArray()
    vtk_colors.SetNumberOfComponents(3)
    vtk_colors.SetName("Colors")
    for i in range(colors.shape[0]):
        vtk_colors.InsertNextTuple3(colors[i, 0], colors[i, 1], colors[i, 2])

    # Set the colors to the polydata
    polydata.GetPointData().SetScalars(vtk_colors)

    # Create a vtkVertexGlyphFilter object and set the input data
    vertex_filter = vtk.vtkVertexGlyphFilter()
    vertex_filter.SetInputData(polydata)
    vertex_filter.Update()

    # Create a vtkPolyDataMapper object and set the input connection
    mapper = vtk.vtkPolyDataMapper()
    mapper.SetInputConnection(vertex_filter.GetOutputPort())

    # Create a vtkActor object and set the mapper
    actor = vtk.vtkActor()
    actor.SetMapper(mapper)
    actor.GetProperty().SetPointSize(point_size)  # Set the point size

    # Create a vtkRenderer object and add the actor
    renderer = vtk.vtkRenderer()
    renderer.AddActor(actor)
    renderer.SetBackground(0.1, 0.2, 0.4)

    # Create a vtkRenderWindow object and add the renderer
    render_window = vtk.vtkRenderWindow()
    render_window.AddRenderer(renderer)
    render_window.SetSize(width, height)

    # Create a vtkRenderWindowInteractor object and set the render window
    render_window_interactor = vtk.vtkRenderWindowInteractor()
    render_window_interactor.SetRenderWindow(render_window)

    # Render the scene
    render_window.Render()

    # Capture the depth buffer
    z_buffer = vtk.vtkFloatArray()
    render_window.GetZbufferData(0, 0, width - 1, height - 1, z_buffer)

    # Convert the depth buffer to a numpy array
    depth_image = np.zeros((height, width), dtype=np.float32)
    for i in range(height):
        for j in range(width):
            depth_image[i, j] = z_buffer.GetValue(i * width + j)

    # Start the interaction
    render_window_interactor.Start()

    return depth_image
# Function to save the transformation matrix and intrinsics



def load_transformation_matrix(file_path):
    """
    Parses transformation and intrinsics matrices from a given text file
    and returns them as NumPy arrays.

    Args:
        file_path (str): The path to the text file containing the matrix data.

    Returns:
        tuple: A tuple containing the transformation matrix (NumPy array)
               and the intrinsics matrix (NumPy array).
               Returns (None, None) if parsing fails, matrices are not found
               with correct dimensions, or the file cannot be read.
    """
    transformation_list = []
    intrinsics_list = []
    current_matrix_type = None # To know which matrix we are currently parsing

    try:
        with open(file_path, 'r') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"Error: File not found at path: {file_path}")
        return None, None
    except Exception as e:
        print(f"Error reading file: {e}")
        return None, None

    for line_num, raw_line in enumerate(lines):
        line = raw_line.strip()
        if not line:
            continue

        if line.startswith("Transformation Matrix:"):
            current_matrix_type = "transformation"
            transformation_list = [] # Reset for new matrix block
            continue
        elif line.startswith("Intrinsics:"):
            current_matrix_type = "intrinsics"
            intrinsics_list = [] # Reset for new matrix block
            continue

        if current_matrix_type:
            try:
                # Split the line and convert to float, handling potential empty strings from multiple spaces
                row = [float(x) for x in line.split() if x]
                if not row: # Skip if the line becomes empty after stripping and splitting (e.g. line of only spaces)
                    continue

                if current_matrix_type == "transformation":
                    # Only add if the row has 4 elements and we haven't completed the matrix
                    if len(transformation_list) < 4:
                        if len(row) == 4:
                            transformation_list.append(row)
                        else:
                            print(f"Warning: Transformation matrix row {len(transformation_list)+1} (line {line_num+1}) has {len(row)} elements, expected 4. Discarding this matrix block.")
                            transformation_list = [] # Invalidate current attempt
                            current_matrix_type = None # Stop parsing this block
                    # If we already have 4 rows, subsequent lines are not part of this matrix
                    elif len(transformation_list) == 4:
                        current_matrix_type = None


                elif current_matrix_type == "intrinsics":
                    # Only add if the row has 3 elements and we haven't completed the matrix
                    if len(intrinsics_list) < 3:
                        if len(row) == 3:
                            intrinsics_list.append(row)
                        else:
                            print(f"Warning: Intrinsics matrix row {len(intrinsics_list)+1} (line {line_num+1}) has {len(row)} elements, expected 3. Discarding this matrix block.")
                            intrinsics_list = [] # Invalidate current attempt
                            current_matrix_type = None # Stop parsing this block
                    # If we already have 3 rows, subsequent lines are not part of this matrix
                    elif len(intrinsics_list) == 3:
                        current_matrix_type = None


            except ValueError:
                print(f"Warning: Could not parse numbers in line {line_num+1}: '{raw_line.strip()}'. Discarding current matrix block.")
                if current_matrix_type == "transformation":
                    transformation_list = []
                elif current_matrix_type == "intrinsics":
                    intrinsics_list = []
                current_matrix_type = None # Stop parsing this block

        # Check if matrices are complete after processing a relevant line
        if current_matrix_type == "transformation" and len(transformation_list) == 4:
            current_matrix_type = None # Done with this matrix
        elif current_matrix_type == "intrinsics" and len(intrinsics_list) == 3:
            current_matrix_type = None # Done with this matrix


    # Convert to NumPy arrays and validate dimensions
    tm_np = None
    if transformation_list and len(transformation_list) == 4 and all(len(row) == 4 for row in transformation_list):
        try:
            tm_np = np.array(transformation_list, dtype=float)
        except Exception as e:
            print(f"Error converting transformation matrix to NumPy array: {e}")
            tm_np = None # Ensure it's None if conversion fails
    elif transformation_list: # If list is populated but not correct shape
        print("Error: Transformation matrix was not fully parsed with correct dimensions (expected 4x4).")


    im_np = None
    if intrinsics_list and len(intrinsics_list) == 3 and all(len(row) == 3 for row in intrinsics_list):
        try:
            im_np = np.array(intrinsics_list, dtype=float)
        except Exception as e:
            print(f"Error converting intrinsics matrix to NumPy array: {e}")
            im_np = None # Ensure it's None if conversion fails
    elif intrinsics_list: # If list is populated but not correct shape
        print("Error: Intrinsics matrix was not fully parsed with correct dimensions (expected 3x3).")

    return tm_np, im_np

def save_transformation_and_intrinsics(transformation_matrix, intrinsics, filename):
    with open(filename, 'w') as f:
        f.write('Transformation Matrix:\n')
        np.savetxt(f, transformation_matrix)
        f.write('\nIntrinsics:\n')
        np.savetxt(f, intrinsics)
# Function to calculate the transformation matrix using solvePnP
def select_points_im(image):
    """ Allows user to select 4 points in an image and returns them. """
    selected_points = []

    def mouse_callback(event, x, y, flags, param):
        """ Handles mouse clicks and stores selected points. """
        if event == cv2.EVENT_LBUTTONDOWN and len(selected_points) < 6:
            selected_points.append((x, y))
            print(f"Point {len(selected_points)} selected: {x}, {y}")

            # Update the image with selected points
            temp_image = image.copy()
            for i, point in enumerate(selected_points):
                cv2.circle(temp_image, point, 5, (0, 0, 255), -1)  # Red dot
                cv2.putText(temp_image, str(i + 1), (point[0] + 5, point[1] - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)  # Yellow number

            cv2.imshow("Select 6 Points", temp_image)

        if len(selected_points) == 4:
            print("All 4 points selected. Press any key to continue.")

    cv2.imshow("Select 6 Points", image)
    cv2.setMouseCallback("Select 6 Points", mouse_callback)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

    if len(selected_points) != 6:
        raise ValueError("You must select exactly 6 points.")

    return selected_points
def calculate_transformation_matrix(points,image_points, intrinsics):
    """ Compute the transformation matrix using SolvePnP. """
    object_points = np.array(points, dtype=np.float32)
    image_points = np.array(image_points, dtype=np.float32)

    success, rotation_vector, translation_vector = cv2.solvePnP(
        object_points, image_points, intrinsics, None
    )

    if not success:
        raise ValueError("solvePnP failed to compute a valid transformation.")

    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)

    transformation_matrix = np.eye(4)
    transformation_matrix[:3, :3] = rotation_matrix
    transformation_matrix[:3, 3] = translation_vector.flatten()

    # --- Calculate RMS Reprojection Error ---
    # Project the 3D points back onto the image plane using the estimated pose
    reprojected_image_points, _ = cv2.projectPoints(
        object_points, rotation_vector, translation_vector, intrinsics, None
    )

    # Squeeze reprojected_image_points from (N, 1, 2) to (N, 2) if necessary
    reprojected_image_points = reprojected_image_points.reshape(-1, 2)

    # Calculate the error for each point
    # The error is the Euclidean distance between the original image points and the reprojected ones
    errors = image_points - reprojected_image_points
    squared_errors = np.sum(errors**2, axis=1) # Sum of squared differences for x and y

    # Calculate Mean Squared Error (MSE)
    mse = np.mean(squared_errors)

    # Calculate Root Mean Square Error (RMSE)
    rms_error = np.sqrt(mse)
    print(f"RMS Reprojection Error: {rms_error:.4f} pixels")

    return transformation_matrix


# Function to select four points
def select_points(XYZ):
    selected_points = []

    def on_left_button_down(obj, event):
        click_pos = obj.GetEventPosition()
        picker = vtk.vtkPointPicker()
        picker.Pick(click_pos[0], click_pos[1], 0, obj.GetRenderWindow().GetRenderers().GetFirstRenderer())
        point_id = picker.GetPointId()
        print('tried to select point')
        if point_id != -1:
            print('selected point')
            selected_points.append(XYZ[point_id])
            if len(selected_points) == 4:
                obj.GetRenderWindow().Finalize()
                obj.TerminateApp()

    render_window_interactor = vtk.vtkRenderWindowInteractor()
    render_window_interactor.AddObserver("LeftButtonPressEvent", on_left_button_down)

    return np.array(selected_points)
def plot_xyz_with_vtk(XYZ, colors):
    points = vtk.vtkPoints()
    for i in range(XYZ.shape[0]):
        points.InsertNextPoint(XYZ[i, :])

    polydata = vtk.vtkPolyData()
    polydata.SetPoints(points)

    vtk_colors = vtk.vtkUnsignedCharArray()
    vtk_colors.SetNumberOfComponents(3)
    vtk_colors.SetName("Colors")
    for i in range(colors.shape[0]):
        vtk_colors.InsertNextTuple3(colors[i, 0], colors[i, 1], colors[i, 2])

    polydata.GetPointData().SetScalars(vtk_colors)

    vertex_filter = vtk.vtkVertexGlyphFilter()
    vertex_filter.SetInputData(polydata)
    vertex_filter.Update()

    mapper = vtk.vtkPolyDataMapper()
    mapper.SetInputConnection(vertex_filter.GetOutputPort())

    actor = vtk.vtkActor()
    actor.SetMapper(mapper)

    renderer = vtk.vtkRenderer()
    renderer.AddActor(actor)
    renderer.SetBackground(0.1, 0.2, 0.4)

    render_window = vtk.vtkRenderWindow()
    render_window.AddRenderer(renderer)

    render_window_interactor = vtk.vtkRenderWindowInteractor()
    render_window_interactor.SetRenderWindow(render_window)

    render_window.Render()
    render_window_interactor.Start()

def detect_and_plot_largest_plane(XYZ,plot = True):
    # Convert the numpy array to an Open3D point cloud
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(XYZ)

    # Detect the largest plane using RANSAC
    plane_model, inliers = pcd.segment_plane(distance_threshold=0.01,
                                             ransac_n=3,
                                             num_iterations=1000)
    inlier_cloud = pcd.select_by_index(inliers)
    outlier_cloud = pcd.select_by_index(inliers, invert=True)

    # Convert the inlier and outlier point clouds back to numpy arrays
    inlier_XYZ = np.asarray(inlier_cloud.points)
    outlier_XYZ = np.asarray(outlier_cloud.points)

    # Plot the original point cloud with the plane points highlighted
    if plot == 1:
        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        ax.scatter(outlier_XYZ[:, 0], outlier_XYZ[:, 1], outlier_XYZ[:, 2], c='b', marker='o', label='Outliers')
        ax.scatter(inlier_XYZ[:, 0], inlier_XYZ[:, 1], inlier_XYZ[:, 2], c='r', marker='o', label='Plane')
        ax.set_xlabel('X')
        ax.set_ylabel('Y')
        ax.set_zlabel('Z')
        plt.legend()
        plt.show()

    [a, b, c, d] = plane_model

    # Extract the normal of the plane
    normal = np.array([a, b, c])

    # Calculate the rotation matrix to align the plane with the XY axis
    z_axis = np.array([0, 1, 0])
    rotation_axis = np.cross(normal, z_axis)
    rotation_angle = np.arccos(np.dot(normal, z_axis) / (np.linalg.norm(normal) * np.linalg.norm(z_axis)))
    rotation_matrix = o3d.geometry.get_rotation_matrix_from_axis_angle(rotation_axis * rotation_angle)

    # Apply the rotation to the point cloud
    pcd.rotate(rotation_matrix)
    # Convert the transformed point cloud back to a numpy array
    transformed_XYZ = np.asarray(pcd.points)
    transformed_XYZ= transformed_XYZ[:, [0, 2, 1]] # something went wrong in the transformation code. lazy fix: Todo: fix the transformation code
    return transformed_XYZ



def fill_depth_image(depth_image):
    # Create a mask for pixels with value larger than 0.9999 or smaller than 0.00001
    mask = (depth_image > 0.9999) | (depth_image < 0.00001)
    # Compute the distance transform
    distance, indices = distance_transform_edt(mask, return_indices=True)

    # Iterate through each pixel in the depth image
    for i in range(depth_image.shape[0]):
        for j in range(depth_image.shape[1]):
            if depth_image[i, j] > 0.9999 or depth_image[i, j] < 0.00001:
                # Get the nearest neighbor's coordinates
                ni, nj = indices[:, i, j]
                if distance[i, j] <= 10 :
                    # Fill the current pixel with the nearest neighbor's value
                    depth_image[i, j] = depth_image[ni, nj]
                else:
                    # Set the current pixel to NaN
                    depth_image[i, j] = np.nan

    return depth_image


import open3d as o3d
import numpy as np

def select_points(pcd):


    print("")
    print(
        "1) Please pick at least three correspondences using [shift + left click]"
    )
    print("   Press [shift + right click] to undo point picking")
    print("2) Afther picking points, press q (or a on azerty) for close the window")
    vis = o3d.visualization.VisualizerWithEditing()
    vis.create_window()
    vis.add_geometry(pcd)
    vis.get_render_option().background_color = [0.86, 0.72, 0.82]

    vis.run()  # user picks points
    vis.destroy_window()
    print("")
    return vis.get_picked_points()


def voxel_upsample(xyz_points, upsample_factor=2, base_voxel_resolution=25):
    """
    Upsamples a point cloud by filling a dense grid within the volume defined by a coarse voxel grid.

    This method is volumetric, meaning it creates points inside the object's volume,
    not just on its surface.

    Args:
        xyz_points (np.ndarray): A NumPy array of shape (N, 3) representing the original point cloud.
        upsample_factor (int): The factor by which to increase the point density. For example,
                               a factor of 2 will create a grid 2x denser on each axis,
                               resulting in approximately 8 times more points.
        base_voxel_resolution (int): Determines the size of the initial coarse voxels. The
                                     bounding box of the point cloud is divided by this number
                                     to set the voxel size. A smaller number creates a coarser
                                     base volume.

    Returns:
        np.ndarray: A new NumPy array of shape (M, 3) with the upsampled points, where M > N.
    """
    # --- 1. Input Validation and Conversion ---
    if not isinstance(xyz_points, np.ndarray) or xyz_points.ndim != 2 or xyz_points.shape[1] != 3:
        raise ValueError("Input `xyz_points` must be a NumPy array with shape (N, 3).")
    if not isinstance(upsample_factor, int) or upsample_factor < 2:
        raise ValueError("`upsample_factor` must be an integer greater than or equal to 2.")
    if xyz_points.shape[0] == 0:
        return np.array([])  # Return empty if input is empty

    # Convert NumPy array to Open3D PointCloud
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(xyz_points)

    # --- 2. Create Coarse Voxel Grid to Define the Volume ---
    # Determine the size of the coarse voxels based on the point cloud's bounding box
    extent = pcd.get_max_bound() - pcd.get_min_bound()
    voxel_size = np.mean(extent) / base_voxel_resolution

    # Create a voxel grid from the point cloud. This grid will represent the object's volume.
    voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size=voxel_size)

    # --- 3. Generate a Dense Grid of Query Points ---
    # Calculate the size for the new, denser voxels
    new_voxel_size = voxel_size / upsample_factor

    # Get the bounds of the original volume to create the new grid within it
    min_bound = voxel_grid.get_min_bound()
    max_bound = voxel_grid.get_max_bound()

    # Create a dense grid of points that spans the entire volume
    x = np.arange(min_bound[0], max_bound[0], new_voxel_size)
    y = np.arange(min_bound[1], max_bound[1], new_voxel_size)
    z = np.arange(min_bound[2], max_bound[2], new_voxel_size)
    xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')
    query_points = np.vstack([xx.ravel(), yy.ravel(), zz.ravel()]).T

    # --- 4. Filter the Dense Grid to Keep Only Points Inside the Volume ---
    # `check_if_included` efficiently checks which of the query points fall within
    # an occupied voxel of the original coarse grid.
    inclusion_mask = voxel_grid.check_if_included(o3d.utility.Vector3dVector(query_points))

    # The new points are the query points that were inside the original volume
    upsampled_points = query_points[inclusion_mask]

    return upsampled_points






def project_and_color_pointcloud_with_border(image, transformation_matrix, intrinsics, point_cloud,
                                 border_size=100, ind=None, upsample=1, vis=1):
    """
    Projects 3D points to 2D, assigns color, and visualizes.

    Includes a controllable border where edge colors are "smeared" outwards.

    Args:
        image: The input image.
        transformation_matrix: The 4x4 transformation matrix (extrinsic).
        intrinsics: The 3x3 camera intrinsic matrix.
        point_cloud: The list or array of 3D points.
        border_size (int): The pixel thickness of the clamped border zone.
                           Points outside this zone will be black. Defaults to 20.
    """
    height, width = image.shape[:2]
    num_points = point_cloud.shape[0]

    # 1. Transform points from world to camera frame
    point_cloud_h = np.hstack((point_cloud, np.ones((num_points, 1))))
    transformed_points = (transformation_matrix @ point_cloud_h.T).T[:, :3]

    # 2. Project points onto the image plane
    projected_h = (intrinsics @ transformed_points.T).T

    # 3. Perspective divide (with robustness check)
    # Filter out points with zero or negative depth to avoid division errors
    depths = projected_h[:, 2]
    valid_depth_mask = depths > 1e-6

    # Initialize projected coordinates and perform division only on valid points
    projected_2d = np.zeros((num_points, 2))
    projected_2d[valid_depth_mask] = projected_h[valid_depth_mask, :2] / depths[valid_depth_mask, np.newaxis]

    # 4. Vectorized color selection
    u = projected_2d[:, 0].astype(int)
    v = projected_2d[:, 1].astype(int)

    # Initialize final colors array (normalized RGB)
    colors = np.zeros((num_points, 3), dtype=np.float32)

    # --- Mask for points inside the image ---
    mask_inside = (u >= 0) & (u < width) & (v >= 0) & (v < height) & valid_depth_mask

    # OPTIMIZATION: Sample BGR colors first, then convert only the sample to RGB.
    if np.any(mask_inside):
        sampled_bgr = image[v[mask_inside], u[mask_inside]]
        # cvtColor needs a 3D array, so we add and remove a dimension
        sampled_rgb = cv2.cvtColor(sampled_bgr[np.newaxis, :], cv2.COLOR_BGR2RGB)[0]
        colors[mask_inside] = sampled_rgb / 255.0

    # --- Mask for points in the border region ---
    mask_border = ~mask_inside & \
                  (u >= -border_size) & (u < width + border_size) & \
                  (v >= -border_size) & (v < height + border_size) & \
                  valid_depth_mask

    colors[mask_border] = np.array([0, 66, 106]) / 255.0  # This is already RGB-like

    # 5. Create Open3D point cloud
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(transformed_points)
    pcd.colors = o3d.utility.Vector3dVector(colors)

    # REFINEMENT: Simplified logic for selecting inliers
    if ind is not None:
        pcd = pcd.select_by_index(ind)

    XYZ = np.asarray(pcd.points)
    final_colors = np.asarray(pcd.colors)

    if vis == 1:
        o3d.visualization.draw_geometries([pcd])

    return final_colors, XYZ






def project_and_color_pointcloud(image, transformation_matrix, intrinsics, point_cloud,ind = None,upsample = 1,vis = 1):
    """ Projects 3D points to 2D, assigns color from the image, and visualizes using Open3D. """
    colors = []
    transformed_points = []
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB

    for point in point_cloud:
        # Convert 3D point to homogeneous coordinates
        point_h = np.array([point[0], point[1], point[2], 1.0])

        # Apply transformation
        transformed_point = transformation_matrix @ point_h
        transformed_point = transformed_point[:3]  # Convert back to 3D
        transformed_points.append(transformed_point)

        # Project 3D point onto the 2D image plane
        projected = intrinsics @ transformed_point
        projected /= projected[2]  # Normalize by depth

        x, y = int(projected[0]), int(projected[1])

        # Check if the projected point is inside the image bounds
        if 0 <= x < image.shape[1] and 0 <= y < image.shape[0]:
            colors.append(image[y, x] / 255.0)  # Normalize to [0, 1] for Open3D
        else:
            colors.append([0, 0, 0])  # Default to black if out of bounds



    # Convert lists to numpy arrays
    transformed_points = np.array(transformed_points)
    colors = np.array(colors)

    # Create Open3D point cloud
    pcd = o3d.geometry.PointCloud()


    pcd.points = o3d.utility.Vector3dVector(transformed_points)
    pcd.colors = o3d.utility.Vector3dVector(colors)

    if ind is not None:
        # Select the inliers
        pcd = pcd.select_by_index(ind)
        XYZ = np.asarray(pcd.points)
        colors = np.asarray(pcd.colors)
    else:
        XYZ = np.asarray(pcd.points)
        colors = np.asarray(pcd.colors)

    # Visualize point cloud
    if vis == 1:
        o3d.visualization.draw_geometries([pcd])
    return colors,XYZ
if __name__ == "__main__":
    # Global variables
    selected_points = []
    image = None




    # Example usage
    pointcloud_file = r"../Data\lidar3\test_2025_06_02__11_11_13_423067"  # Example filename without extension
    #pointcloud_file = r"Data\lidar2\test_2025_06_02__11_10_43_538027"
    pointcloud_file = r"../Data\lidar1\test_2025_06_02__11_10_12_992218"

    # Read the point cloud
    points_xyz_list, points_rgb_list = read_point_cloud_from_files(pointcloud_file)

    # get the "image" and "colors" for a specific frame number and save to ply.
    framenumber = 2
    XYZ = points_xyz_list[framenumber]
    colors = points_rgb_list[framenumber] #note, there is only info in the Green channel. So this probably needs to be chaned to an intensity value.
    output_file = 'outputlidar.ply'
    # Create an Open3D point cloud
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(XYZ)
    #pcd.colors = o3d.utility.Vector3dVector(colors/255 )
    cl, ind = pcd.remove_statistical_outlier(nb_neighbors=20,
                                             std_ratio=2.0)

    pcd = pcd.select_by_index(ind)
    selected_indices = select_points(pcd)
    selected_points = np.asarray(pcd.points)[selected_indices]
    p1_numpy = selected_points[0,:]
    p2_numpy = selected_points[1,:]
    distance_numpy = np.linalg.norm(p1_numpy - p2_numpy)

    # Load the image
    image_path = r"../Data\camera3_converted_undistort\test_2025-06-02_11-11-10\0001.jpeg"  # Change to your image file
    #image_path = r"Data\camera2_converted_undistort\test_2025-06-02_11-10-41\0001.jpeg"# Change to your image file
    image_path = r"../Data\camera1_converted_undistort\test_2025-06-02_11-10-09\0020.jpeg"
    image = cv2.imread(image_path)

    if image is None:
        print("Error: Could not load image.")


    selected_points_im = select_points_im(image)



    # Example camera intrinsic matrix (Modify this with actual values)
    intrinsics = np.array([
        [1770.69, 0, 685.3],  # Focal length in x, skew (usually 0), principal point x
        [0, 1765.03, 492.7],  # 0, focal length in y, principal point y
        [0, 0, 1]
    ], dtype=np.float32)

    transformation_matrix = calculate_transformation_matrix(selected_points,selected_points_im, intrinsics)

    print("Computed Transformation Matrix:")
    transformation_matrix = calculate_transformation_matrix(selected_points, selected_points_im, intrinsics)
    save_transformation_and_intrinsics(transformation_matrix, intrinsics, 'transformation_and_intrinsics6.txt')
    save_as_ply(XYZ, colors, output_file)


    project_and_color_pointcloud(image, transformation_matrix, intrinsics, XYZ,ind)


    # add a histogram slider



